# ‚úÖ –ü–û–õ–ù–û–°–¢–¨–Æ –†–ê–ë–û–ß–ò–ô –ö–û–î –î–õ–Ø GOOGLE COLAB - –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô np.stack
# ========================================================

# 1. –£–°–¢–ê–ù–û–í–ö–ê –ó–ê–í–ò–°–ò–ú–û–°–¢–ï–ô
!pip install -q ipywidgets matplotlib seaborn plotly tensorflow

# 2. –ò–ú–ü–û–†–¢–´
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import ipywidgets as widgets
from IPython.display import display, HTML, clear_output
import pandas as pd
import warnings
warnings.filterwarnings('ignore')

print("‚úÖ –í—Å–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã! üöÄ")

# 3. ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –ì–ï–ù–ï–†–ê–¶–ò–Ø –°–ü–£–¢–ù–ò–ö–û–í–´–• –î–ê–ù–ù–´–• (–ë–ï–ó np.stack –æ—à–∏–±–æ–∫)
print("üõ∞Ô∏è –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã—Ö —Å–ø—É—Ç–Ω–∏–∫–æ–≤—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π...")

def generate_satellite_dataset(n_samples=2000, img_size=128, n_classes=10):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ë–ï–ó broadcasting –∏ stack –æ—à–∏–±–æ–∫"""
    X, y = [], []
    class_names = ['–ì–æ—Ä–æ–¥', '–õ–µ—Å', '–ü–æ–ª–µ', '–í–æ–¥–∞', '–ì–æ—Ä—ã', 
                   '–î–æ—Ä–æ–≥–∞', '–ü—É—Å—Ç—ã–Ω—è', '–°–Ω–µ–≥', '–§–µ—Ä–º–∞', '–ü–æ–±–µ—Ä–µ–∂—å–µ']
    
    for class_id in range(n_classes):
        for _ in range(n_samples // n_classes):
            # –ë–∞–∑–æ–≤–æ–µ RGB –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            img = np.random.rand(img_size, img_size, 3).astype(np.float32)
            
            # ‚úÖ –ü–†–û–°–¢–´–ï –û–ü–ï–†–ê–¶–ò–ò –ü–û –ö–ê–ù–ê–õ–ê–ú (–±–µ–∑ stack)
            if class_id == 0:  # –ì–æ—Ä–æ–¥ - —Å–µ—Ç–∫–∞
                x_coords = np.linspace(0, 10*np.pi, img_size)
                y_coords = np.linspace(0, 10*np.pi, img_size)
                xx, yy = np.meshgrid(x_coords, y_coords, indexing='ij')
                grid_pattern = np.sin(xx) * np.sin(yy)
                img[:, :, 0] += 0.3 * grid_pattern  # –ö—Ä–∞—Å–Ω—ã–π –∫–∞–Ω–∞–ª
                img[:, :, 1] += 0.2 * grid_pattern  # –ó–µ–ª–µ–Ω—ã–π –∫–∞–Ω–∞–ª
                
            elif class_id == 1:  # –õ–µ—Å - –∑–µ–ª–µ–Ω—ã–π
                forest_noise = np.random.rand(img_size, img_size) * 0.4
                img[:, :, 1] += forest_noise  # –£—Å–∏–ª–µ–Ω–∏–µ –∑–µ–ª–µ–Ω–æ–≥–æ
                
            elif class_id == 2:  # –ü–æ–ª–µ - –∂–µ–ª—Ç–æ–µ
                img[:, 60:, 0] += 0.3  # –ñ–µ–ª—Ç—ã–π –æ—Ç—Ç–µ–Ω–æ–∫
                
            elif class_id == 3:  # –í–æ–¥–∞ - —Å–∏–Ω–∏–π
                img[:, :, 2] += 0.4
                wave_pattern = np.sin(np.linspace(0, 20*np.pi, img_size)[:, None])
                img[:, :, 0] += 0.2 * wave_pattern
                
            elif class_id == 4:  # –ì–æ—Ä—ã
                height_map = np.sin(np.linspace(0, 5*np.pi, img_size)[:, None] * 2)
                img[:, :, 0] += 0.4 * height_map  # –¢–µ–Ω–∏
                
            # –®—É–º –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
            img += np.random.normal(0, 0.03, img.shape)
            img = np.clip(img, 0, 1)
            
            X.append(img)
            y.append(class_id)
    
    return np.array(X), np.array(y), class_names

# –ì–ï–ù–ï–†–ê–¶–ò–Ø
X, y, class_names = generate_satellite_dataset()
print(f"‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(X)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, {len(class_names)} –∫–ª–∞—Å—Å–æ–≤")
print(f"‚úÖ –§–æ—Ä–º–∞: X={X.shape}, y={y.shape}")

# 4. –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø –ö–õ–ê–°–°–û–í
fig, axes = plt.subplots(2, 5, figsize=(20, 8))
for i, class_name in enumerate(class_names):
    class_imgs = X[y == i]
    sample = class_imgs[0]
    axes[i//5, i%5].imshow(sample)
    axes[i//5, i%5].set_title(class_name, fontsize=12)
    axes[i//5, i%5].axis('off')
plt.suptitle('üõ∞Ô∏è –ü—Ä–∏–º–µ—Ä—ã —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö —Å–ø—É—Ç–Ω–∏–∫–æ–≤—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π', fontsize=16)
plt.tight_layout()
plt.show()

# 5. –†–ê–ó–î–ï–õ–ï–ù–ò–ï –î–ê–ù–ù–´–•
X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp)
print(f"üìä Train: {len(X_train)} | Val: {len(X_val)} | Test: {len(X_test)}")

# 6. CNN –ú–û–î–ï–õ–¨
def create_cnn(input_shape=(128, 128, 3), num_classes=len(class_names)):
    model = keras.Sequential([
        # –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è
        layers.RandomFlip("horizontal_and_vertical"),
        layers.RandomRotation(0.1),
        layers.RandomZoom(0.1),
        
        # Conv Block 1
        layers.Conv2D(32, 3, activation='relu', input_shape=input_shape),
        layers.BatchNormalization(),
        layers.Conv2D(32, 3, activation='relu'),
        layers.MaxPooling2D(2),
        layers.Dropout(0.25),
        
        # Conv Block 2
        layers.Conv2D(64, 3, activation='relu'),
        layers.BatchNormalization(),
        layers.Conv2D(64, 3, activation='relu'),
        layers.MaxPooling2D(2),
        layers.Dropout(0.25),
        
        # Conv Block 3
        layers.Conv2D(128, 3, activation='relu'),
        layers.BatchNormalization(),
        layers.GlobalAveragePooling2D(),
        
        # Dense
        layers.Dense(256, activation='relu'),
        layers.Dropout(0.5),
        layers.Dense(num_classes, activation='softmax')
    ])
    return model

model = create_cnn()
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
print(model.summary())

# 7. –û–ë–£–ß–ï–ù–ò–ï
callbacks = [
    keras.callbacks.EarlyStopping(patience=15, restore_best_weights=True),
    keras.callbacks.ReduceLROnPlateau(patience=5)
]

print("\nüöÄ –û–ë–£–ß–ï–ù–ò–ï...")
history = model.fit(X_train, y_train, validation_data=(X_val, y_val),
                   epochs=50, batch_size=32, callbacks=callbacks, verbose=1)

# 8. –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï
test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)
print(f"\nüéØ –¢–æ—á–Ω–æ—Å—Ç—å: {test_acc:.4f}")

y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)

# 9. DASHBOARD
fig = make_subplots(rows=1, cols=2, subplot_titles=('–¢–æ—á–Ω–æ—Å—Ç—å', '–ü–æ—Ç–µ—Ä–∏'))
epochs = range(1, len(history.history['accuracy'])+1)
fig.add_trace(go.Scatter(x=epochs, y=history.history['accuracy'], name='Train'), 1, 1)
fig.add_trace(go.Scatter(x=epochs, y=history.history['val_accuracy'], name='Val'), 1, 1)
fig.add_trace(go.Scatter(x=epochs, y=history.history['loss'], name='Train Loss'), 1, 2)
fig.add_trace(go.Scatter(x=epochs, y=history.history['val_loss'], name='Val Loss'), 1, 2)
fig.update_layout(height=500, title="üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è")
fig.show()

# 10. –ò–ù–¢–ï–†–ê–ö–¢–ò–í–ù–´–ô –ü–†–û–°–ú–û–¢–†
@widgets.interact(idx=(0, len(X_test)-1))
def show_sample(idx):
    pred = model.predict(X_test[idx:idx+1], verbose=0)[0]
    pred_class = np.argmax(pred)
    true_class = class_names[y_test[idx]]
    
    fig, axes = plt.subplots(1, 2, figsize=(12, 5))
    axes[0].imshow(X_test[idx])
    color = 'green' if pred_class == y_test[idx] else 'red'
    axes[0].set_title(f'–ü—Ä–∞–≤–¥–∞: {true_class}\n–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: {class_names[pred_class]}\n{pred[pred_class]:.1%}', 
                     color=color, fontsize=14)
    axes[0].axis('off')
    
    axes[1].bar(range(len(class_names)), pred, color='skyblue')
    axes[1].bar(pred_class, pred[pred_class], color='gold')
    axes[1].set_xticks(range(len(class_names)))
    axes[1].set_xticklabels([c[:8] for c in class_names], rotation=45)
    axes[1].set_title('–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏')
    plt.tight_layout()
    plt.show()

# 11. –°–û–•–†–ê–ù–ï–ù–ò–ï
model.save('satellite_cnn_final.h5')
print("\nüíæ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞!")
print("üéâ –°–ò–°–¢–ï–ú–ê –†–ê–ë–û–¢–ê–ï–¢ –ë–ï–ó –û–®–ò–ë–û–ö!")
